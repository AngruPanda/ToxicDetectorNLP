{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞\" data-toc-modified-id=\"–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞</a></span><ul class=\"toc-item\"><li><span><a href=\"#–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π-–∏—Ç–æ–≥\" data-toc-modified-id=\"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π-–∏—Ç–æ–≥-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∏—Ç–æ–≥</a></span></li></ul></li><li><span><a href=\"#–û–±—É—á–µ–Ω–∏–µ\" data-toc-modified-id=\"–û–±—É—á–µ–Ω–∏–µ-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>–û–±—É—á–µ–Ω–∏–µ</a></span><ul class=\"toc-item\"><li><span><a href=\"#–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ-–≤—ã–≤–æ–¥—ã\" data-toc-modified-id=\"–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ-–≤—ã–≤–æ–¥—ã-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>–ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –≤—ã–≤–æ–¥—ã</a></span></li></ul></li><li><span><a href=\"#–í—ã–≤–æ–¥—ã\" data-toc-modified-id=\"–í—ã–≤–æ–¥—ã-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>–í—ã–≤–æ–¥—ã</a></span></li><li><span><a href=\"#–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏\" data-toc-modified-id=\"–ß–µ–∫-–ª–∏—Å—Ç-–ø—Ä–æ–≤–µ—Ä–∫–∏-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>–ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –ü—Ä–æ–µ–∫—Ç –¥–ª—è ¬´–í–∏–∫–∏—à–æ–ø¬ª"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ò–Ω—Ç–µ—Ä–Ω–µ—Ç-–º–∞–≥–∞–∑–∏–Ω ¬´–í–∏–∫–∏—à–æ–ø¬ª –∑–∞–ø—É—Å–∫–∞–µ—Ç –Ω–æ–≤—ã–π —Å–µ—Ä–≤–∏—Å. –¢–µ–ø–µ—Ä—å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–∏ –º–æ–≥—É—Ç —Ä–µ–¥–∞–∫—Ç–∏—Ä–æ–≤–∞—Ç—å –∏ –¥–æ–ø–æ–ª–Ω—è—Ç—å –æ–ø–∏—Å–∞–Ω–∏—è —Ç–æ–≤–∞—Ä–æ–≤, –∫–∞–∫ –≤ –≤–∏–∫–∏-—Å–æ–æ–±—â–µ—Å—Ç–≤–∞—Ö. –¢–æ –µ—Å—Ç—å –∫–ª–∏–µ–Ω—Ç—ã –ø—Ä–µ–¥–ª–∞–≥–∞—é—Ç —Å–≤–æ–∏ –ø—Ä–∞–≤–∫–∏ –∏ –∫–æ–º–º–µ–Ω—Ç–∏—Ä—É—é—Ç –∏–∑–º–µ–Ω–µ–Ω–∏—è –¥—Ä—É–≥–∏—Ö. –ú–∞–≥–∞–∑–∏–Ω—É –Ω—É–∂–µ–Ω –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π –±—É–¥–µ—Ç –∏—Å–∫–∞—Ç—å —Ç–æ–∫—Å–∏—á–Ω—ã–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –∏ –æ—Ç–ø—Ä–∞–≤–ª—è—Ç—å –∏—Ö –Ω–∞ –º–æ–¥–µ—Ä–∞—Ü–∏—é. \n",
    "\n",
    "–û–±—É—á–∏—Ç–µ –º–æ–¥–µ–ª—å –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –Ω–∞ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –∏ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–µ. –í –≤–∞—à–µ–º —Ä–∞—Å–ø–æ—Ä—è–∂–µ–Ω–∏–∏ –Ω–∞–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å —Ä–∞–∑–º–µ—Ç–∫–æ–π –æ —Ç–æ–∫—Å–∏—á–Ω–æ—Å—Ç–∏ –ø—Ä–∞–≤–æ–∫.\n",
    "\n",
    "–ü–æ—Å—Ç—Ä–æ–π—Ç–µ –º–æ–¥–µ–ª—å —Å–æ –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞ *F1* –Ω–µ –º–µ–Ω—å—à–µ 0.75. \n",
    "\n",
    "**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è –ø–æ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—é –ø—Ä–æ–µ–∫—Ç–∞**\n",
    "\n",
    "1. –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏ –ø–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ –¥–∞–Ω–Ω—ã–µ.\n",
    "2. –û–±—É—á–∏—Ç–µ —Ä–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏. \n",
    "3. –°–¥–µ–ª–∞–π—Ç–µ –≤—ã–≤–æ–¥—ã.\n",
    "\n",
    "–î–ª—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –ø—Ä–æ–µ–∫—Ç–∞ –ø—Ä–∏–º–µ–Ω—è—Ç—å *BERT* –Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ, –Ω–æ –≤—ã –º–æ–∂–µ—Ç–µ –ø–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å.\n",
    "\n",
    "**–û–ø–∏—Å–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö**\n",
    "\n",
    "–î–∞–Ω–Ω—ã–µ –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ —Ñ–∞–π–ª–µ `toxic_comments.csv`. –°—Ç–æ–ª–±–µ—Ü *text* –≤ –Ω—ë–º —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è, –∞ *toxic* ‚Äî —Ü–µ–ª–µ–≤–æ–π –ø—Ä–∏–∑–Ω–∞–∫."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–≤—ã–º –¥–µ–ª–æ–º –∑–∞–≥—Ä—É–∑–∏–º –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–ª—è —Ä–∞–±–æ—Ç—ã –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ –¥–∞–Ω–Ω—ã–µ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aleks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Aleks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aleks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aleks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –¥–∞–Ω–Ω—ã—Ö\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#NLP –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –¥–ª—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∏ –¥–∞–Ω–Ω—ã—Ö \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "#–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#–ú–æ–¥–µ–ª–∏ —É—á–∞—Å—Ç–≤—É—é—â–∏–µ –≤ –æ—Ç–±–æ—Ä–µ –∏ –º–µ—Ç—Ä–∏–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "#–ö–æ–Ω—Å—Ç–∞–Ω—Ç—ã –∏ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "RANDOM_STATE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ó–∞–≥—Ä—É–∑–∏–º –¥–∞–Ω–Ω—ã–µ, —É–∫–∞–∑–∞–≤ –ø–µ—Ä–≤—ã–º —Å—Ç–æ–ª–±—Ü–æ–º –∏–Ω–¥–µ–∫—Å—ã."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv', index_col='Unnamed: 0')\n",
    "except:\n",
    "    data = pd.read_csv('C:/Users/Aleks/Desktop/–ú–∞–≥–∞/–Ø–Ω–¥–µ–∫—Å/–ü—Ä–æ–µ–∫—Ç –ø–æ NLP/toxic_comments.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–æ–≤–µ–¥–µ–º –ø–µ—Ä–≤–∏—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–Ω–Ω—ã–µ —Å–æ–æ—Ç–≤–µ—Ç—Å–≤—É—é –æ–ø–∏—Å–∞–Ω–∏—é –∏ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç –∫–∞–∫–∏—Ö-—Ç–æ —è–≤–Ω—ã—Ö —Å–µ—Ä—å–µ–∑–Ω—ã—Ö –ø—Ä–æ–±–ª–µ–º. –ü–æ—Å–º–æ—Ç—Ä–∏–º –Ω–∞–ª–∏—á–∏–µ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ –¥–∞–Ω–Ω—ã—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–ß–∏—Å–ª–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö - 0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"–ß–∏—Å–ª–æ –ø—Ä–æ–ø—É—Å–∫–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö - {data['text'].isna().sum()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'–ß–∏—Å–ª–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö - 0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"–ß–∏—Å–ª–æ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö - {data['text'].duplicated().sum()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –≤–∏–¥–Ω–æ –≤ –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –Ω–∏ –ø—Ä–æ–ø—É—Å–∫–æ–≤, –Ω–∏ –¥—É–±–ª–∏–∫–∞—Ç–æ–≤, —á—Ç–æ –Ω–µ –º–æ–∂–µ—Ç –Ω–µ —Ä–∞–¥–æ–≤–∞—Ç—å. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –¥–æ—Å—Ç—É–ø–Ω—ã–π —á–∏—Å–ª–æ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä toxic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize= (5, 5))\n",
    "plt.pie(data['toxic'].value_counts(), autopct = lambda x: '%.2f' % x + '%', labels=data['toxic'].value_counts().index)\n",
    "plt.title('–ö—Ä—É–≥–æ–≤–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞ - —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ç–æ–∫—Å–∏—á–Ω—ã—Ö –∏ –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–µ–≤')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ù–∞ –ª–∏—Ü–æ –¥–∏—Å–±–∞–ª–∞–Ω—Å –∫–ª–∞—Å—Å–æ–≤ - —ç—Ç–æ –≤–∞–∂–Ω–æ –±—É–¥–µ—Ç —É—á–µ—Å—Ç—å, –ø—Ä–∏ —Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ –¥–∞–Ω–Ω—ã—Ö –Ω–∞ –≤—ã–±–æ—Ä–∫–∏, —É–∫–∞–∑–∞–≤ –ø–∞—Ä–∞–º–µ—Ç—Ä stratify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–ª–ª–µ –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Ç—â–µ—Ç–Ω–∞—è –ø–æ–ø—ã—Ç–∫–∞ —Ä–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å —Å—Ö–µ–º—É —ç–º–±–µ–Ω–¥–∏–Ω–≥–æ–≤ —Å BERT. –ü–æ–Ω—è–ª —á—Ç–æ –º–æ–π –ü–ö –Ω–µ –ø–æ—Ç—è–Ω–µ—Ç —Ç–∞–∫—É—é –∑–∞–¥–∞—á—É - 27 —á–∞—Å–æ–≤ –Ω–∞ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –≤—Å–µ—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤, –∞ –ø–æ—Ç–æ–º –µ—â–µ –±–æ–ª—å—à–µ –Ω–∞ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π. –í–æ–∑–º–æ–∂–Ω–æ –≥–¥–µ-—Ç–æ —É –º–µ–Ω—è –µ—Å—Ç—å –∑–¥–µ—Å—å –æ—à–∏–±–∫–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nimport torch\\nimport transformers\\nfrom tqdm import notebook \\n\\ntokenizer = transformers.BertTokenizer(\\n    vocab_file=\"C:/Users/Aleks/Desktop/–ú–∞–≥–∞/–Ø–Ω–¥–µ–∫—Å/BERT/vocab.txt\")\\n\\nafter_tokenaizer = data[\\'text\\'].apply(\\n    lambda x: tokenizer.encode(x, add_special_tokens=True))\\n\\nafter_tokenaizer = after_tokenaizer[after_tokenaizer.agg(func=len) <= 512]\\n\\nmax_len = max(after_tokenaizer.agg(func=len))\\n\\npadded = np.array([i + [0]*(max_len - len(i)) for i in after_tokenaizer.values])\\n\\nattention_mask = np.where(padded != 0, 1, 0)\\n\\nconfig = transformers.BertConfig.from_json_file(\\n    \\'C:/Users/Aleks/Desktop/–ú–∞–≥–∞/–Ø–Ω–¥–µ–∫—Å/BERT/config.json\\')\\n\\nmodel = transformers.BertModel.from_pretrained(\\n    \\'C:/Users/Aleks/Desktop/–ú–∞–≥–∞/–Ø–Ω–¥–µ–∫—Å/BERT/pytorch_model.bin\\', config=config)\\n\\nbatch_size = 150\\nembeddings = []\\nfor i in notebook.tqdm(range(padded.shape[0] // batch_size)):\\n        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \\n        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\\n        \\n        with torch.no_grad():\\n            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\\n        \\n        embeddings.append(batch_embeddings[0][:,0,:].numpy())\\n        \\nfeatures = np.concatenate(embeddings)\\n27 —á–∞—Å–æ–≤ –Ω–∞ –≤—Å–µüíÄ\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook \n",
    "\n",
    "tokenizer = transformers.BertTokenizer(\n",
    "    vocab_file=\"C:/Users/Aleks/Desktop/–ú–∞–≥–∞/–Ø–Ω–¥–µ–∫—Å/BERT/vocab.txt\")\n",
    "\n",
    "after_tokenaizer = data['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "after_tokenaizer = after_tokenaizer[after_tokenaizer.agg(func=len) <= 512]\n",
    "\n",
    "max_len = max(after_tokenaizer.agg(func=len))\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in after_tokenaizer.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "config = transformers.BertConfig.from_json_file(\n",
    "    'C:/Users/Aleks/Desktop/–ú–∞–≥–∞/–Ø–Ω–¥–µ–∫—Å/BERT/config.json')\n",
    "\n",
    "model = transformers.BertModel.from_pretrained(\n",
    "    'C:/Users/Aleks/Desktop/–ú–∞–≥–∞/–Ø–Ω–¥–µ–∫—Å/BERT/pytorch_model.bin', config=config)\n",
    "\n",
    "batch_size = 150\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "        \n",
    "features = np.concatenate(embeddings)\n",
    "27 —á–∞—Å–æ–≤ –Ω–∞ –≤—Å–µüíÄ\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü—Ä–∏—Å—Ç—É–ø–∏–º –∫ –ø–æ–¥–≥–æ—Ç–æ–≤–∫–µ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è. –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –±—É–¥–µ—Ç —Å–æ—Å—Ç–æ—è—Ç—å –∏–∑ –¥–≤—É—Ö —ç—Ç–∞–ø–æ–≤:\n",
    "1. –õ–µ–º–º–∞—Ç–∏–∑–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ–±—â–µ–Ω–∏—è - –ø—Ä–∏–≤–µ–¥–µ–Ω–∏–µ —Å–ª–æ–≤ –∫ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–º—É –≤–∏–¥—É\n",
    "2. –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –æ—Ç –Ω–µ–Ω—É–∂–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤\n",
    "\n",
    "–†–µ–∞–ª–∏–∑—É–∏—Ç—Å—è –¥–∞–Ω–Ω—ã–µ —à–∞–≥–∏ —á–µ—Ä–µ–∑ —Å–æ–∑–¥–∞–Ω–∏–µ —Ñ—É–Ω–∫—Ü–∏–π —Å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–º–∏ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞–º–∏ –∏ –ø–æ—Å–ª–µ–¥—É—é—â–∏–º –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ–º –∏—Ö –∫ –∫–∞–∂–¥–æ–º—É —ç–ª–µ–º–µ–Ω—Ç—É —Ç–∞–±–ª–∏—Ü—ã. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits make under my username hardcore metallica fan be revert they be n t vandalisms just closure on some gas after i vote at new york doll fac and please do n t remove the template from the talk page since i m retired now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he match this background colour i m seemingly stick with thanks talk january utc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not try to edit war it s just that this guy be constantly remove relevant information and talk to me through edits instead of my talk page he seem to care more about the formatting than the actual info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i ca n t make any real suggestion on improvement i wonder if the section statistic should be later on or a subsection of type of accident i think the reference may need tidy so that they be all in the exact same format ie date format etc i can do that later on if no one else do first if you have any preference for format style on reference or want to do it yourself please let me know there appear to be a backlog on article for review so i guess there may be a delay until a reviewer turn up it s list in the relevant form eg wikipedia good article nominations transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir be my hero any chance you remember what page that s on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>and for the second time of ask when your view completely contradict the coverage in reliable source why should anyone care what you feel you ca n t even give a consistent argument be the open only suppose to mention significant aspect or the most significant one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>you should be ashamed of yourself that be a horrible thing you put on my talk page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>spitzer umm theres no actual article for prostitution ring crunch captain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>and it look like it be actually you who put on the speedy to have the first version delete now that i look at it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>and i really do n t think you understand i come here and my idea be bad right away what kind of community go you have bad idea go away instead of help rewrite them</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    corpus\n",
       "0                                                                                                                                                                                                                                                                                                                                                       explanation why the edits make under my username hardcore metallica fan be revert they be n t vandalisms just closure on some gas after i vote at new york doll fac and please do n t remove the template from the talk page since i m retired now\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   d aww he match this background colour i m seemingly stick with thanks talk january utc\n",
       "2                                                                                                                                                                                                                                                                                                                                                                             hey man i m really not try to edit war it s just that this guy be constantly remove relevant information and talk to me through edits instead of my talk page he seem to care more about the formatting than the actual info\n",
       "3       more i ca n t make any real suggestion on improvement i wonder if the section statistic should be later on or a subsection of type of accident i think the reference may need tidy so that they be all in the exact same format ie date format etc i can do that later on if no one else do first if you have any preference for format style on reference or want to do it yourself please let me know there appear to be a backlog on article for review so i guess there may be a delay until a reviewer turn up it s list in the relevant form eg wikipedia good article nominations transport\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           you sir be my hero any chance you remember what page that s on\n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...\n",
       "159287                                                                                                                                                                                                                                                                                                                              and for the second time of ask when your view completely contradict the coverage in reliable source why should anyone care what you feel you ca n t even give a consistent argument be the open only suppose to mention significant aspect or the most significant one\n",
       "159288                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  you should be ashamed of yourself that be a horrible thing you put on my talk page\n",
       "159289                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           spitzer umm theres no actual article for prostitution ring crunch captain\n",
       "159290                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    and it look like it be actually you who put on the speedy to have the first version delete now that i look at it\n",
       "159291                                                                                                                                                                                                                                                                                                                                                                                                                                 and i really do n t think you understand i come here and my idea be bad right away what kind of community go you have bad idea go away instead of help rewrite them\n",
       "\n",
       "[159292 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return wn.NOUN\n",
    "\n",
    "def clear_text(text):\n",
    "    \n",
    "    return \" \".join( re.sub(r'[^a-zA-Z ]', ' ', text).split() )\n",
    "\n",
    "data_prep =[]\n",
    "\n",
    "for i in data.index:\n",
    "    sentence = data.loc[i, 'text'].lower()\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged = pos_tag(tokens)\n",
    "    \n",
    "    lemmatized_words = []\n",
    "    for word, tag in tagged:\n",
    "        wordnet_tag = get_wordnet_pos(tag)\n",
    "        lemma = wnl.lemmatize(word, pos=wordnet_tag)\n",
    "        lemmatized_words.append(lemma)    \n",
    "   \n",
    "    data_prep.append(' '.join(lemmatized_words))\n",
    "\n",
    "for i in range(len(data_prep)):\n",
    "    data_prep[i] = clear_text(data_prep[i])\n",
    "\n",
    "data_prep = pd.DataFrame(data_prep, columns = ['corpus'])\n",
    "\n",
    "data_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ú—ã –ø–æ–¥–≥–æ—Ç–æ–≤–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –∫ –æ–±—É—á–µ–Ω–∏—é –º–æ–¥–µ–ª–µ–π, —Ç–µ–ø–µ—Ä—å —Ä–∞–∑–æ–±—å–µ–º –∏—Ö –Ω–∞ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω—É—é –∏ —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫–∏ –≤ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–∏ 8:2, —É–∫–∞–∑–∞–≤ –ø—Ä–∏ —ç—Ç–æ–º –ø–∞—Ä–∞–º–µ—Ç—Ä stratify=data['toxic']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_prep,\n",
    "    data['toxic'],\n",
    "    test_size= 0.20,\n",
    "    stratify = data['toxic'],\n",
    "    random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π –∏—Ç–æ–≥"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. –ó–∞–≥—Ä—É–∂–µ–Ω—ã –æ—Å–Ω–æ–≤–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏\n",
    "2. –ó–∞–≥—Ä—É–∂–µ–Ω—ã –¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–æ–≤–µ—Ä–µ–Ω—ã –Ω–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å–≤–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è–º\n",
    "3. –î–∞–Ω–Ω—ã–µ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–∏–Ω—ã –∏ —Ä–∞–∑–¥–µ–ª–µ–Ω—ã –Ω–∞ –≤—ã–±–æ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ü–µ—Ä–µ—Ö–æ–¥–∏–º –∫ —ç—Ç–∞–ø—É –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—é –ø–∞–π–ø–ª–∞–π–Ω–æ–≤. –í—Å—é –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫—É –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –ø–∞–π–ø–ª–∞–π–Ω–æ–≤ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ –≤–Ω—É—Ç—Ä–∏ —Ñ—É–Ω–∫—Ü–∏–∏, –≤ –∫–æ—Ç–æ—Ä—É—é –±—É–¥–µ—Ç –ø–µ—Ä–µ–¥–æ–≤–∞—Ç—å—Å—è –æ–¥–Ω–∞ –º–æ–¥–µ–ª—å –∏ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –ø–æ–¥–±–æ—Ä–∞ –≤ —Å–≤—è–∑–∏ —Å –∫—Ä–∞–π–Ω–µ –¥–ª–∏—Ç–µ–ª—å–Ω—ã–º –ø—Ä–æ—Ü–µ—Å—Å–æ–º –æ–±—É—á–µ–Ω–∏—è."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_search(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    model, \n",
    "    params\n",
    "):\n",
    "    data_preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('tfidf', TfidfVectorizer(stop_words = stopwords), 'corpus') # –£–∫–∞–∑—ã–≤–∞–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä stop_words, –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –±–µ—Å—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö —Å–ª–æ–≤\n",
    "    ], \n",
    "    remainder='passthrough')\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect', data_preprocessor),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        pipeline, \n",
    "        params, \n",
    "        cv=5,\n",
    "        n_jobs=1,\n",
    "        scoring='f1', # –ú–µ—Ç—Ä–∏–∫–∞ f1 –ø–æ –¢–ó\n",
    "        error_score= 0.1\n",
    "    ) \n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    #–¢–∞–∫–∂–µ –≤—ã–≤–µ–¥–µ–º —Ç–∞–±–ª–∏—Ü—É —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–æ–≤–µ–¥–µ–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è\n",
    "    res = pd.DataFrame(grid.cv_results_)[['rank_test_score', 'mean_test_score','params']].sort_values('rank_test_score')\n",
    "\n",
    "    return grid, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–§—É–Ω–∫—Ü–∏—è –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –≥–æ—Ç–æ–≤–∞, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –∫ –æ–±—É—á–µ–Ω–∏—é."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "params = [{\n",
    "    'vect__tfidf__ngram_range': ((1, 2), (1, 3)),\n",
    "    'vect__tfidf__max_features': (10000, 5000),\n",
    "    'clf__C': (0.7, 0.9),\n",
    "    'clf__penalty': ('none', 'l2')\n",
    "}]\n",
    "\n",
    "data_grids_log_reg, table_log_reg = model_pipeline_search(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    LogisticRegression(max_iter=1000, random_state=RANDOM_STATE), \n",
    "    params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.744130</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.744130</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.742422</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.742422</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>0.727721</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>0.727028</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0.726404</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>0.724355</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.715866</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.715485</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.714921</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.708190</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>0.708190</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.692668</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.692668</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  \\\n",
       "3                 1         0.744130   \n",
       "11                1         0.744130   \n",
       "2                 3         0.742422   \n",
       "10                3         0.742422   \n",
       "13                5         0.727721   \n",
       "14                6         0.727028   \n",
       "12                7         0.726404   \n",
       "15                8         0.724355   \n",
       "6                 9         0.717000   \n",
       "7                10         0.715866   \n",
       "5                11         0.715485   \n",
       "4                12         0.714921   \n",
       "1                13         0.708190   \n",
       "9                13         0.708190   \n",
       "0                15         0.692668   \n",
       "8                15         0.692668   \n",
       "\n",
       "                                                                                                             params  \n",
       "3    {'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "11   {'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "2    {'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "10   {'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "13    {'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "14     {'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "12    {'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "15     {'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "6      {'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "7      {'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "5     {'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "4     {'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "1   {'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "9   {'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "0   {'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "8   {'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–û–±—É—á–µ–Ω–∏–µ –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏ –∑–∞–Ω—è–ª–æ –æ–∫–æ–ª–æ 10 –º–∏–Ω—É—Ç –∏ –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –º—ã –≤–∏–¥–∏–º, —á—Ç–æ –ø—Ä–∏ —É–º–µ–Ω—å—à–µ–Ω–∏–∏ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–≥–æ —á–∏—Å–ª–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ TfidfVectorizer –º–µ—Ç—Ä–∏–∫–∞ —Ä–∞—Å—Ç–µ—Ç, –Ω–æ –Ω–µ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç —Ç—Ä–µ–±—É–µ–º—ã—Ö 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\n",
    "    'vect__tfidf__ngram_range': ((1, 2), (1, 1)),\n",
    "    'vect__tfidf__max_features':(3000, 5000)\n",
    "}]\n",
    "\n",
    "data_grids_tree, table_tree = model_pipeline_search(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    DecisionTreeClassifier(random_state=RANDOM_STATE), \n",
    "    params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.690193</td>\n",
       "      <td>{'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 1)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.680607</td>\n",
       "      <td>{'vect__tfidf__max_features': 3000, 'vect__tfidf__ngram_range': (1, 1)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.680545</td>\n",
       "      <td>{'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.669657</td>\n",
       "      <td>{'vect__tfidf__max_features': 3000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score  \\\n",
       "3                1         0.690193   \n",
       "1                2         0.680607   \n",
       "2                3         0.680545   \n",
       "0                4         0.669657   \n",
       "\n",
       "                                                                    params  \n",
       "3  {'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 1)}  \n",
       "1  {'vect__tfidf__max_features': 3000, 'vect__tfidf__ngram_range': (1, 1)}  \n",
       "2  {'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "0  {'vect__tfidf__max_features': 3000, 'vect__tfidf__ngram_range': (1, 2)}  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–î–∞–Ω–Ω–∞—è –º–æ–¥–µ–ª—å –æ–±—É—á–∞–ª–∞—Å—å 15, —Ç–∞–∫–∂–µ –∑–∞–º–µ—Ç–Ω–æ —á—Ç–æ DecisionTreeClassifier —á—É—Å—Ç–≤—É–µ—Ç —Å–µ–±—è —á—É—Ç—å –ª—É—á—à–µ —Å —É–Ω–∏–≥—Ä–∞–º–º–∞–º–∏, –Ω–æ –º–µ—Ç—Ä–∏–∫–∞ —Ç–æ–∂–µ –Ω–µ –¥–æ—Å—Ç–∏–≥–∞–µ—Ç –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\n",
    "    'vect__tfidf__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__tfidf__max_features':(8000, 5000)\n",
    "}]\n",
    "\n",
    "data_grids_forest, table_forest = model_pipeline_search(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    RandomForestClassifier(random_state=RANDOM_STATE), \n",
    "    params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.750326</td>\n",
       "      <td>{'vect__tfidf__max_features': 8000, 'vect__tfidf__ngram_range': (1, 1)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.749422</td>\n",
       "      <td>{'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 1)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.747260</td>\n",
       "      <td>{'vect__tfidf__max_features': 8000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.741051</td>\n",
       "      <td>{'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score  \\\n",
       "0                1         0.750326   \n",
       "2                2         0.749422   \n",
       "1                3         0.747260   \n",
       "3                4         0.741051   \n",
       "\n",
       "                                                                    params  \n",
       "0  {'vect__tfidf__max_features': 8000, 'vect__tfidf__ngram_range': (1, 1)}  \n",
       "2  {'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 1)}  \n",
       "1  {'vect__tfidf__max_features': 8000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "3  {'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ö–∞–∫ –∏ –ø—Ä–µ–¥—ã–¥—É—â–∞—è –º–æ–¥–µ–ª—å RandomForestClassifier –æ–±—É—á–∞–ª–∞—Å—å –æ–∫–æ–ª–æ 1 —á–∞—Å–∞, –Ω–æ –ø—Ä–∏ —ç—Ç–æ–º –µ–π —É–¥–∞–ª–æ—Å—å –¥–æ—Å—Ç–∏—á—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π. –ú–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –ø–æ–ø—Ä–æ–±—ã–≤–∞—Ç—å –µ—â–µ —É–ª—É—á—à–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ —É–≤–µ–ª–∏—á–∏–≤ max_features –∏ n –≥—Ä–∞–º–º—É. \n",
    "\n",
    "–ù–∞–∏–ª—É—á—à–∏–º –æ–±—Ä–∞–∑–æ–º –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ —Å–µ–±—è –ø–æ–∫–∞–∑–∞–ª–∞ RandomForestClassifier, –ø–æ—ç—Ç–æ–º—É –∏ –≤—ã–±–∏—Ä–∞–µ–º —ç—Ç—É –º–æ–¥–µ–ª—å –∫–∞–∫ –ª—É—á—à—É—é. –ü—Ä–æ—Ç–µ—Å—Ç–∏—Ä—É–µ–º –µ–µ –Ω–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_grids_forest.best_estimator_['vect'].transform(X_test)\n",
    "\n",
    "result_test = data_grids_forest.best_estimator_['clf'].predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ú–µ—Ç—Ä–∏–∫–∞ f1 –¥–ª—è –º–æ–¥–µ–ª–∏ RandomForestClassifier –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ - 0.7558423439134985\n"
     ]
    }
   ],
   "source": [
    "print(f'–ú–µ—Ç—Ä–∏–∫–∞ f1 –¥–ª—è –º–æ–¥–µ–ª–∏ RandomForestClassifier –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ - {f1_score(y_test, result_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–õ—É—á—à–∞—è –º–æ–¥–µ–ª—å –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–ª–∞ —Å–≤–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ —Ç—Ä–µ–±—É–µ–º–æ–µ –ø–æ –¢–ó –∑–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–æ—Å—Ç–∏–≥–Ω—É—Ç–æ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ –≤—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. –°–æ—Å—Ç–∞–≤–ª–µ–Ω–∞ —Ñ—É–Ω–∫—Ü–∏—è —Å –ø–∞–π–ø–ª–∞–π–Ω–æ–º –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n",
    "2. –ë—ã–ª–∏ –æ–±—É—á–µ–Ω—ã LogisticRegression, DecisionTreeClassifier, RandomForestClassifier —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏ TfidfVectorizer\n",
    "3. –õ—É—á—à–∏–º –æ–±—Ä–∞–∑–æ–º —Å–µ–±—è –ø–æ–∫–∞–∑–∞–ª–∞ RandomForestClassifier —Å –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ —á—É—Ç—å –±–æ–ª—å—à–µ 0.75 –∏ –ø–æ—Ç–æ–º –ø–æ–¥—Ç–≤–µ—Ä–¥–∏–≤ –µ–≥–æ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –í—ã–≤–æ–¥—ã"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "–ë—ã–ª–∞ –æ–±—É—á–µ–Ω–∞ –º–æ–¥–µ–ª—å RandomForestClassifier —Å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–º –∑–Ω–∞—á–µ–Ω–∏–µ–º –º–µ—Ç—Ä–∏–∫–∏ f1, –¥–ª—è —ç—Ç–æ–≥–æ –º—ã –∑–∞–≥—Ä—É–∑–∏–ª–∏ –¥–∞–Ω–Ω—ã–µ –∏ –ø—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∞–ª–∏ –∏—Ö. –ú–æ–∂–Ω–æ –±—ã–ª–æ –±—ã –≤ –±—É–¥—É—â–µ–º —É–ª—É—á—à–∏—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç –º–æ–¥–µ–ª–∏ —É–≤–µ–ª–∏—á–∏–≤ max_features –∏ n-–≥—Ä–∞–º–º—É –∏–ª–∏ –ø–æ–ø—Ä–æ–±—ã–≤–∞–≤ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–≤ —Å—Ö–µ–º—É —ç–º–±–µ–Ω–¥–∏–Ω–≥–æ–≤ —Å BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## –ß–µ–∫-–ª–∏—Å—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook –æ—Ç–∫—Ä—ã—Ç\n",
    "- [x]  –í–µ—Å—å –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç—Å—è –±–µ–∑ –æ—à–∏–±–æ–∫\n",
    "- [x]  –Ø—á–µ–π–∫–∏ —Å –∫–æ–¥–æ–º —Ä–∞—Å–ø–æ–ª–æ–∂–µ–Ω—ã –≤ –ø–æ—Ä—è–¥–∫–µ –∏—Å–ø–æ–ª–Ω–µ–Ω–∏—è\n",
    "- [x]  –î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã –∏ –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω—ã\n",
    "- [x]  –ú–æ–¥–µ–ª–∏ –æ–±—É—á–µ–Ω—ã\n",
    "- [x]  –ó–Ω–∞—á–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏ *F1* –Ω–µ –º–µ–Ω—å—à–µ 0.75\n",
    "- [x]  –í—ã–≤–æ–¥—ã –Ω–∞–ø–∏—Å–∞–Ω—ã"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 455,
    "start_time": "2025-08-29T10:09:36.475Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-29T10:09:42.288Z"
   },
   {
    "duration": 1187,
    "start_time": "2025-08-29T10:10:54.056Z"
   },
   {
    "duration": 31,
    "start_time": "2025-08-29T10:10:58.958Z"
   },
   {
    "duration": 76,
    "start_time": "2025-08-29T12:12:23.633Z"
   },
   {
    "duration": 1015,
    "start_time": "2025-08-29T12:12:32.092Z"
   },
   {
    "duration": 16,
    "start_time": "2025-08-29T12:12:33.110Z"
   },
   {
    "duration": 1026,
    "start_time": "2025-08-29T12:12:39.338Z"
   },
   {
    "duration": 12,
    "start_time": "2025-08-29T12:12:40.930Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-29T12:13:08.791Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-29T12:13:15.171Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-29T12:13:29.504Z"
   },
   {
    "duration": 39,
    "start_time": "2025-08-29T12:13:44.122Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-29T12:13:56.491Z"
   },
   {
    "duration": 8,
    "start_time": "2025-08-29T12:34:55.606Z"
   },
   {
    "duration": 32,
    "start_time": "2025-08-29T12:37:50.725Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-29T12:38:05.736Z"
   },
   {
    "duration": 10,
    "start_time": "2025-08-29T12:38:17.546Z"
   },
   {
    "duration": 11,
    "start_time": "2025-08-29T12:38:27.907Z"
   },
   {
    "duration": 85,
    "start_time": "2025-08-29T12:38:44.096Z"
   },
   {
    "duration": 32,
    "start_time": "2025-08-29T12:39:42.575Z"
   },
   {
    "duration": 30,
    "start_time": "2025-08-29T12:50:12.442Z"
   },
   {
    "duration": 34,
    "start_time": "2025-08-29T12:50:57.263Z"
   },
   {
    "duration": 1552,
    "start_time": "2025-08-29T13:08:37.377Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-29T13:19:57.521Z"
   },
   {
    "duration": 164,
    "start_time": "2025-08-29T13:21:36.790Z"
   },
   {
    "duration": 123,
    "start_time": "2025-08-29T13:23:03.544Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
