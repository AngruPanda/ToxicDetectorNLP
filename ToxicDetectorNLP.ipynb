{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Промежуточный-итог\" data-toc-modified-id=\"Промежуточный-итог-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Промежуточный итог</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#Промежуточные-выводы\" data-toc-modified-id=\"Промежуточные-выводы-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Промежуточные выводы</a></span></li></ul></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первым делом загрузим необходимые для работы библиотеки и данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Aleks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Aleks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Aleks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Aleks\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Стандартные библиотеки для анализа данных\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#NLP библиотеки для подготовки данных \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk import pos_tag\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = set(stopwords.words('english'))\n",
    "#Построение пайплайнов для обучения моделей\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#Модели участвующие в отборе и метрика для проверки\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "#Константы и настройки\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "RANDOM_STATE = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим данные, указав первым столбцом индексы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('/datasets/toxic_comments.csv', index_col='Unnamed: 0')\n",
    "except:\n",
    "    data = pd.read_csv('C:/Users/Aleks/Desktop/Мага/Яндекс/Проект по NLP/toxic_comments.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проведем первичный анализ данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember what page that's on?</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                           Explanation\\nWhy the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                           Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.   \n",
       "3  \"\\nMore\\nI can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\\n\\nThere appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 You, sir, are my hero. Any chance you remember what page that's on?   \n",
       "\n",
       "   toxic  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные соответсвую описанию и не содержат каких-то явных серьезных проблем. Посмотрим наличие дубликатов и пропусков в данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Число пропусков в сообщениях - 0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Число пропусков в сообщениях - {data['text'].isna().sum()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Число дубликатов в сообщениях - 0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"Число дубликатов в сообщениях - {data['text'].duplicated().sum()}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видно в данных нет ни пропусков, ни дубликатов, что не может не радовать. Проанализируем единственный доступный числовой параметр toxic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize= (5, 5))\n",
    "plt.pie(data['toxic'].value_counts(), autopct = lambda x: '%.2f' % x + '%', labels=data['toxic'].value_counts().index)\n",
    "plt.title('Круговая диаграмма - соотношение токсичных и позитивных комментариев')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На лицо дисбаланс классов - это важно будет учесть, при разделении данных на выборки, указав параметр stratify."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далле присутствует тщетная попытка реализовать схему эмбендингов с BERT. Понял что мой ПК не потянет такую задачу - 27 часов на построение всех признаков, а потом еще больше на обучение моделей. Возможно где-то у меня есть здесь ошибка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\nimport torch\\nimport transformers\\nfrom tqdm import notebook \\n\\ntokenizer = transformers.BertTokenizer(\\n    vocab_file=\"C:/Users/Aleks/Desktop/Мага/Яндекс/BERT/vocab.txt\")\\n\\nafter_tokenaizer = data[\\'text\\'].apply(\\n    lambda x: tokenizer.encode(x, add_special_tokens=True))\\n\\nafter_tokenaizer = after_tokenaizer[after_tokenaizer.agg(func=len) <= 512]\\n\\nmax_len = max(after_tokenaizer.agg(func=len))\\n\\npadded = np.array([i + [0]*(max_len - len(i)) for i in after_tokenaizer.values])\\n\\nattention_mask = np.where(padded != 0, 1, 0)\\n\\nconfig = transformers.BertConfig.from_json_file(\\n    \\'C:/Users/Aleks/Desktop/Мага/Яндекс/BERT/config.json\\')\\n\\nmodel = transformers.BertModel.from_pretrained(\\n    \\'C:/Users/Aleks/Desktop/Мага/Яндекс/BERT/pytorch_model.bin\\', config=config)\\n\\nbatch_size = 150\\nembeddings = []\\nfor i in notebook.tqdm(range(padded.shape[0] // batch_size)):\\n        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \\n        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\\n        \\n        with torch.no_grad():\\n            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\\n        \\n        embeddings.append(batch_embeddings[0][:,0,:].numpy())\\n        \\nfeatures = np.concatenate(embeddings)\\n27 часов на все💀\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from tqdm import notebook \n",
    "\n",
    "tokenizer = transformers.BertTokenizer(\n",
    "    vocab_file=\"C:/Users/Aleks/Desktop/Мага/Яндекс/BERT/vocab.txt\")\n",
    "\n",
    "after_tokenaizer = data['text'].apply(\n",
    "    lambda x: tokenizer.encode(x, add_special_tokens=True))\n",
    "\n",
    "after_tokenaizer = after_tokenaizer[after_tokenaizer.agg(func=len) <= 512]\n",
    "\n",
    "max_len = max(after_tokenaizer.agg(func=len))\n",
    "\n",
    "padded = np.array([i + [0]*(max_len - len(i)) for i in after_tokenaizer.values])\n",
    "\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "config = transformers.BertConfig.from_json_file(\n",
    "    'C:/Users/Aleks/Desktop/Мага/Яндекс/BERT/config.json')\n",
    "\n",
    "model = transformers.BertModel.from_pretrained(\n",
    "    'C:/Users/Aleks/Desktop/Мага/Яндекс/BERT/pytorch_model.bin', config=config)\n",
    "\n",
    "batch_size = 150\n",
    "embeddings = []\n",
    "for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "        batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "        attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "        embeddings.append(batch_embeddings[0][:,0,:].numpy())\n",
    "        \n",
    "features = np.concatenate(embeddings)\n",
    "27 часов на все💀\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Приступим к подготовке данных для обучения. Подготовка будет состоять из двух этапов:\n",
    "1. Лемматизации текста сообщения - приведение слов к первоначальному виду\n",
    "2. Очистка текста от ненужных символов\n",
    "\n",
    "Реализуится данные шаги через создание функций с соответствующими библиотеками и последующим применением их к каждому элементу таблицы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits make under my username hardcore metallica fan be revert they be n t vandalisms just closure on some gas after i vote at new york doll fac and please do n t remove the template from the talk page since i m retired now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he match this background colour i m seemingly stick with thanks talk january utc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not try to edit war it s just that this guy be constantly remove relevant information and talk to me through edits instead of my talk page he seem to care more about the formatting than the actual info</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i ca n t make any real suggestion on improvement i wonder if the section statistic should be later on or a subsection of type of accident i think the reference may need tidy so that they be all in the exact same format ie date format etc i can do that later on if no one else do first if you have any preference for format style on reference or want to do it yourself please let me know there appear to be a backlog on article for review so i guess there may be a delay until a reviewer turn up it s list in the relevant form eg wikipedia good article nominations transport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir be my hero any chance you remember what page that s on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159287</th>\n",
       "      <td>and for the second time of ask when your view completely contradict the coverage in reliable source why should anyone care what you feel you ca n t even give a consistent argument be the open only suppose to mention significant aspect or the most significant one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159288</th>\n",
       "      <td>you should be ashamed of yourself that be a horrible thing you put on my talk page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159289</th>\n",
       "      <td>spitzer umm theres no actual article for prostitution ring crunch captain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159290</th>\n",
       "      <td>and it look like it be actually you who put on the speedy to have the first version delete now that i look at it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159291</th>\n",
       "      <td>and i really do n t think you understand i come here and my idea be bad right away what kind of community go you have bad idea go away instead of help rewrite them</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159292 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    corpus\n",
       "0                                                                                                                                                                                                                                                                                                                                                       explanation why the edits make under my username hardcore metallica fan be revert they be n t vandalisms just closure on some gas after i vote at new york doll fac and please do n t remove the template from the talk page since i m retired now\n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   d aww he match this background colour i m seemingly stick with thanks talk january utc\n",
       "2                                                                                                                                                                                                                                                                                                                                                                             hey man i m really not try to edit war it s just that this guy be constantly remove relevant information and talk to me through edits instead of my talk page he seem to care more about the formatting than the actual info\n",
       "3       more i ca n t make any real suggestion on improvement i wonder if the section statistic should be later on or a subsection of type of accident i think the reference may need tidy so that they be all in the exact same format ie date format etc i can do that later on if no one else do first if you have any preference for format style on reference or want to do it yourself please let me know there appear to be a backlog on article for review so i guess there may be a delay until a reviewer turn up it s list in the relevant form eg wikipedia good article nominations transport\n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           you sir be my hero any chance you remember what page that s on\n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ...\n",
       "159287                                                                                                                                                                                                                                                                                                                              and for the second time of ask when your view completely contradict the coverage in reliable source why should anyone care what you feel you ca n t even give a consistent argument be the open only suppose to mention significant aspect or the most significant one\n",
       "159288                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  you should be ashamed of yourself that be a horrible thing you put on my talk page\n",
       "159289                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           spitzer umm theres no actual article for prostitution ring crunch captain\n",
       "159290                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    and it look like it be actually you who put on the speedy to have the first version delete now that i look at it\n",
       "159291                                                                                                                                                                                                                                                                                                                                                                                                                                 and i really do n t think you understand i come here and my idea be bad right away what kind of community go you have bad idea go away instead of help rewrite them\n",
       "\n",
       "[159292 rows x 1 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wn.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wn.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wn.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wn.ADV\n",
    "    else:\n",
    "        return wn.NOUN\n",
    "\n",
    "def clear_text(text):\n",
    "    \n",
    "    return \" \".join( re.sub(r'[^a-zA-Z ]', ' ', text).split() )\n",
    "\n",
    "data_prep =[]\n",
    "\n",
    "for i in data.index:\n",
    "    sentence = data.loc[i, 'text'].lower()\n",
    "    tokens = word_tokenize(sentence)\n",
    "    tagged = pos_tag(tokens)\n",
    "    \n",
    "    lemmatized_words = []\n",
    "    for word, tag in tagged:\n",
    "        wordnet_tag = get_wordnet_pos(tag)\n",
    "        lemma = wnl.lemmatize(word, pos=wordnet_tag)\n",
    "        lemmatized_words.append(lemma)    \n",
    "   \n",
    "    data_prep.append(' '.join(lemmatized_words))\n",
    "\n",
    "for i in range(len(data_prep)):\n",
    "    data_prep[i] = clear_text(data_prep[i])\n",
    "\n",
    "data_prep = pd.DataFrame(data_prep, columns = ['corpus'])\n",
    "\n",
    "data_prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы подготовили данные к обучению моделей, теперь разобьем их на тренировочную и тестовую выборки в соотношении 8:2, указав при этом параметр stratify=data['toxic']."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data_prep,\n",
    "    data['toxic'],\n",
    "    test_size= 0.20,\n",
    "    stratify = data['toxic'],\n",
    "    random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточный итог"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Загружены основные библиотеки\n",
    "2. Загружены данные и проверены на соответсвие требованиям\n",
    "3. Данные подготовлины и разделены на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переходим к этапу построению пайплайнов. Всю предобработку и построение пайплайнов реализованно внутри функции, в которую будет передоваться одна модель и параметры для подбора в связи с крайне длительным процессом обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_pipeline_search(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    model, \n",
    "    params\n",
    "):\n",
    "    data_preprocessor = ColumnTransformer(\n",
    "    [\n",
    "        ('tfidf', TfidfVectorizer(stop_words = stopwords), 'corpus') # Указываем параметр stop_words, для удаления бессмысленных слов\n",
    "    ], \n",
    "    remainder='passthrough')\n",
    "    \n",
    "    pipeline = Pipeline([\n",
    "        ('vect', data_preprocessor),\n",
    "        ('clf', model)\n",
    "    ])\n",
    "    \n",
    "    grid = GridSearchCV(\n",
    "        pipeline, \n",
    "        params, \n",
    "        cv=5,\n",
    "        n_jobs=1,\n",
    "        scoring='f1', # Метрика f1 по ТЗ\n",
    "        error_score= 0.1\n",
    "    ) \n",
    "    \n",
    "    grid.fit(X_train, y_train)\n",
    "    #Также выведем таблицу с результатами для анализа проведенного обучения\n",
    "    res = pd.DataFrame(grid.cv_results_)[['rank_test_score', 'mean_test_score','params']].sort_values('rank_test_score')\n",
    "\n",
    "    return grid, res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция для обучения готова, переходим к обучению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1322: UserWarning: Setting penalty='none' will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "C:\\Users\\Aleks\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "params = [{\n",
    "    'vect__tfidf__ngram_range': ((1, 2), (1, 3)),\n",
    "    'vect__tfidf__max_features': (10000, 5000),\n",
    "    'clf__C': (0.7, 0.9),\n",
    "    'clf__penalty': ('none', 'l2')\n",
    "}]\n",
    "\n",
    "data_grids_log_reg, table_log_reg = model_pipeline_search(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    LogisticRegression(max_iter=1000, random_state=RANDOM_STATE), \n",
    "    params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.744130</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>0.744130</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.742422</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>0.742422</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5</td>\n",
       "      <td>0.727721</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>0.727028</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7</td>\n",
       "      <td>0.726404</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>8</td>\n",
       "      <td>0.724355</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>0.715866</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11</td>\n",
       "      <td>0.715485</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.714921</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.708190</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13</td>\n",
       "      <td>0.708190</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0.692668</td>\n",
       "      <td>{'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>15</td>\n",
       "      <td>0.692668</td>\n",
       "      <td>{'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    rank_test_score  mean_test_score  \\\n",
       "3                 1         0.744130   \n",
       "11                1         0.744130   \n",
       "2                 3         0.742422   \n",
       "10                3         0.742422   \n",
       "13                5         0.727721   \n",
       "14                6         0.727028   \n",
       "12                7         0.726404   \n",
       "15                8         0.724355   \n",
       "6                 9         0.717000   \n",
       "7                10         0.715866   \n",
       "5                11         0.715485   \n",
       "4                12         0.714921   \n",
       "1                13         0.708190   \n",
       "9                13         0.708190   \n",
       "0                15         0.692668   \n",
       "8                15         0.692668   \n",
       "\n",
       "                                                                                                             params  \n",
       "3    {'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "11   {'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "2    {'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "10   {'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "13    {'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "14     {'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "12    {'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "15     {'clf__C': 0.9, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "6      {'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "7      {'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "5     {'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "4     {'clf__C': 0.7, 'clf__penalty': 'l2', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "1   {'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "9   {'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 3)}  \n",
       "0   {'clf__C': 0.7, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "8   {'clf__C': 0.9, 'clf__penalty': 'none', 'vect__tfidf__max_features': 10000, 'vect__tfidf__ngram_range': (1, 2)}  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_log_reg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение логистической регрессии заняло около 10 минут и в результате мы видим, что при уменьшении максимального числа признаков TfidfVectorizer метрика растет, но не достигает требуемых 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\n",
    "    'vect__tfidf__ngram_range': ((1, 2), (1, 1)),\n",
    "    'vect__tfidf__max_features':(3000, 5000)\n",
    "}]\n",
    "\n",
    "data_grids_tree, table_tree = model_pipeline_search(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    DecisionTreeClassifier(random_state=RANDOM_STATE), \n",
    "    params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0.690193</td>\n",
       "      <td>{'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 1)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.680607</td>\n",
       "      <td>{'vect__tfidf__max_features': 3000, 'vect__tfidf__ngram_range': (1, 1)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.680545</td>\n",
       "      <td>{'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.669657</td>\n",
       "      <td>{'vect__tfidf__max_features': 3000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score  \\\n",
       "3                1         0.690193   \n",
       "1                2         0.680607   \n",
       "2                3         0.680545   \n",
       "0                4         0.669657   \n",
       "\n",
       "                                                                    params  \n",
       "3  {'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 1)}  \n",
       "1  {'vect__tfidf__max_features': 3000, 'vect__tfidf__ngram_range': (1, 1)}  \n",
       "2  {'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "0  {'vect__tfidf__max_features': 3000, 'vect__tfidf__ngram_range': (1, 2)}  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данная модель обучалась 15, также заметно что DecisionTreeClassifier чуствует себя чуть лучше с униграммами, но метрика тоже не достигает необходимых значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [{\n",
    "    'vect__tfidf__ngram_range': ((1, 1), (1, 2)),\n",
    "    'vect__tfidf__max_features':(8000, 5000)\n",
    "}]\n",
    "\n",
    "data_grids_forest, table_forest = model_pipeline_search(\n",
    "    X_train, \n",
    "    y_train, \n",
    "    RandomForestClassifier(random_state=RANDOM_STATE), \n",
    "    params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.750326</td>\n",
       "      <td>{'vect__tfidf__max_features': 8000, 'vect__tfidf__ngram_range': (1, 1)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.749422</td>\n",
       "      <td>{'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 1)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.747260</td>\n",
       "      <td>{'vect__tfidf__max_features': 8000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.741051</td>\n",
       "      <td>{'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rank_test_score  mean_test_score  \\\n",
       "0                1         0.750326   \n",
       "2                2         0.749422   \n",
       "1                3         0.747260   \n",
       "3                4         0.741051   \n",
       "\n",
       "                                                                    params  \n",
       "0  {'vect__tfidf__max_features': 8000, 'vect__tfidf__ngram_range': (1, 1)}  \n",
       "2  {'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 1)}  \n",
       "1  {'vect__tfidf__max_features': 8000, 'vect__tfidf__ngram_range': (1, 2)}  \n",
       "3  {'vect__tfidf__max_features': 5000, 'vect__tfidf__ngram_range': (1, 2)}  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как и предыдущая модель RandomForestClassifier обучалась около 1 часа, но при этом ей удалось достичь необходимых значений. Можно было бы попробывать еще улучшить значение метрики увеличив max_features и n грамму. \n",
    "\n",
    "Наилучшим образом при обучении себя показала RandomForestClassifier, поэтому и выбираем эту модель как лучшую. Протестируем ее на тестовых данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_grids_forest.best_estimator_['vect'].transform(X_test)\n",
    "\n",
    "result_test = data_grids_forest.best_estimator_['clf'].predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика f1 для модели RandomForestClassifier на тестовой выборке - 0.7558423439134985\n"
     ]
    }
   ],
   "source": [
    "print(f'Метрика f1 для модели RandomForestClassifier на тестовой выборке - {f1_score(y_test, result_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лучшая модель подтвердила свой результат и требуемое по ТЗ значение метрики достигнуто."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Промежуточные выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Составлена функция с пайплайном для обучения моделей\n",
    "2. Были обучены LogisticRegression, DecisionTreeClassifier, RandomForestClassifier с различными параметрами TfidfVectorizer\n",
    "3. Лучшим образом себя показала RandomForestClassifier с значением метрики чуть больше 0.75 и потом подтвердив его на тестовой выборке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Была обучена модель RandomForestClassifier с необходимым значением метрики f1, для этого мы загрузили данные и предобработали их. Можно было бы в будущем улучшить результат модели увеличив max_features и n-грамму или попробывав реализовав схему эмбендингов с BERT."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Чек-лист проверки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x]  Jupyter Notebook открыт\n",
    "- [x]  Весь код выполняется без ошибок\n",
    "- [x]  Ячейки с кодом расположены в порядке исполнения\n",
    "- [x]  Данные загружены и подготовлены\n",
    "- [x]  Модели обучены\n",
    "- [x]  Значение метрики *F1* не меньше 0.75\n",
    "- [x]  Выводы написаны"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 455,
    "start_time": "2025-08-29T10:09:36.475Z"
   },
   {
    "duration": 3,
    "start_time": "2025-08-29T10:09:42.288Z"
   },
   {
    "duration": 1187,
    "start_time": "2025-08-29T10:10:54.056Z"
   },
   {
    "duration": 31,
    "start_time": "2025-08-29T10:10:58.958Z"
   },
   {
    "duration": 76,
    "start_time": "2025-08-29T12:12:23.633Z"
   },
   {
    "duration": 1015,
    "start_time": "2025-08-29T12:12:32.092Z"
   },
   {
    "duration": 16,
    "start_time": "2025-08-29T12:12:33.110Z"
   },
   {
    "duration": 1026,
    "start_time": "2025-08-29T12:12:39.338Z"
   },
   {
    "duration": 12,
    "start_time": "2025-08-29T12:12:40.930Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-29T12:13:08.791Z"
   },
   {
    "duration": 9,
    "start_time": "2025-08-29T12:13:15.171Z"
   },
   {
    "duration": 4,
    "start_time": "2025-08-29T12:13:29.504Z"
   },
   {
    "duration": 39,
    "start_time": "2025-08-29T12:13:44.122Z"
   },
   {
    "duration": 7,
    "start_time": "2025-08-29T12:13:56.491Z"
   },
   {
    "duration": 8,
    "start_time": "2025-08-29T12:34:55.606Z"
   },
   {
    "duration": 32,
    "start_time": "2025-08-29T12:37:50.725Z"
   },
   {
    "duration": 18,
    "start_time": "2025-08-29T12:38:05.736Z"
   },
   {
    "duration": 10,
    "start_time": "2025-08-29T12:38:17.546Z"
   },
   {
    "duration": 11,
    "start_time": "2025-08-29T12:38:27.907Z"
   },
   {
    "duration": 85,
    "start_time": "2025-08-29T12:38:44.096Z"
   },
   {
    "duration": 32,
    "start_time": "2025-08-29T12:39:42.575Z"
   },
   {
    "duration": 30,
    "start_time": "2025-08-29T12:50:12.442Z"
   },
   {
    "duration": 34,
    "start_time": "2025-08-29T12:50:57.263Z"
   },
   {
    "duration": 1552,
    "start_time": "2025-08-29T13:08:37.377Z"
   },
   {
    "duration": 5,
    "start_time": "2025-08-29T13:19:57.521Z"
   },
   {
    "duration": 164,
    "start_time": "2025-08-29T13:21:36.790Z"
   },
   {
    "duration": 123,
    "start_time": "2025-08-29T13:23:03.544Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
