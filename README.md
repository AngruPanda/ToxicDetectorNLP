## Задача
Обучить модель отделять токсичные и хорошие комментарии. В распоряжении около 160 тысяч комментариев на английском языке
## Работа
Можно было пойти двумя путями:
- через лемматизацию и tf-idf диаграмму
- через BERT
Попыталяс сделать и так, и так. В результате используя BERT весь процесс займет порядка 27 часов, поэтому пойдем по другому пути.
Удалим все бессмысленные символы, лемматизируем с удалением стоп-слов. Сам tf-idf преобразователь встроил в пайплайн, чтобы переберать
параметры максимального кол-ва признаков, тк их кол-во какое-то запредельное и обучение длится около 6 часов, поэтому сделаем потолок
в количестве примерно в 60000. Ну и соответственно будем обучать относительно простые модели LogReg, RandomForest, DecisionTree.
## Итог
Лучшим образом себя показал случайный лес, метрика соответсвует ТЗ и подтверждена на тестовой выборке
## Возможные доработки 
Все таки довести до ума вариант с BERT, мне кажется так можно улучшить метрику на 15-20%
